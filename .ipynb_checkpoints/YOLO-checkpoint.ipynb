{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83afc03a-48ca-48df-b6fd-299095d92295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images DataFrame:\n",
      "   id                                              image\n",
      "0   0  b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00...\n",
      "\n",
      "Labels DataFrame:\n",
      "    image_id    x    y  orientation  radius  class\n",
      "0          0  269  450     0.000000      17      0\n",
      "1          0  533  299     0.663225      45      1\n",
      "2          0  539  427     0.610865      46      1\n",
      "3          0  365  148     0.488692      45      1\n",
      "4          0  472  136     2.426008      40      1\n",
      "5          0  846  448     4.660029      41      1\n",
      "6          0  613  248     6.003933      41      1\n",
      "7          0  287  214     2.391101      48      1\n",
      "8          0  657  387     5.393067      44      1\n",
      "9          0  752  311     2.792527      41      1\n",
      "10         0  657  134     2.565634      49      1\n",
      "11         0  699  245     3.019420      38      1\n",
      "12         0  308  382     4.537856      39      2\n",
      "13         0  926  116     6.021386      39      2\n",
      "14         0  398  398     0.506145      42      2\n",
      "15         0  774  120     3.333579      47      2\n",
      "16         0  221  307     5.724680      48      2\n",
      "17         0  129  390     3.106686      49      2\n",
      "18         0  362  275     2.234021      38      2\n",
      "19         0  173  181     1.727876      41      2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the images and labels from the parquet files\n",
    "images_df = pd.read_parquet('images.parquet')\n",
    "labels_df = pd.read_parquet('labels.parquet')\n",
    "\n",
    "# Inspect the loaded data\n",
    "print(\"Images DataFrame:\")\n",
    "print(images_df.head(1))\n",
    "print(\"\\nLabels DataFrame:\")\n",
    "print(labels_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dfbbeaf-7125-463a-adcd-a752c4c4bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def decode_image(image_data):\n",
    "    nparr = np.frombuffer(image_data, np.uint8)\n",
    "    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "    return img\n",
    "\n",
    "images_df['image'] = images_df['image'].apply(decode_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d6bd638-9f89-4f6e-aaf4-54c23da54a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images DataFrame shape:\n",
      "(500, 2)\n",
      "First image\n",
      "   id                                              image\n",
      "0   0  [[[17, 123, 57], [18, 124, 58], [18, 124, 58],...\n",
      "\n",
      "Labels DataFrame shape:\n",
      "(11500, 6)\n",
      "\n",
      "First label:\n",
      "   image_id    x    y  orientation  radius  class\n",
      "0         0  269  450     0.000000      17      0\n",
      "1         0  533  299     0.663225      45      1\n",
      "2         0  539  427     0.610865      46      1\n",
      "3         0  365  148     0.488692      45      1\n",
      "4         0  472  136     2.426008      40      1\n",
      "5         0  846  448     4.660029      41      1\n",
      "6         0  613  248     6.003933      41      1\n",
      "7         0  287  214     2.391101      48      1\n",
      "8         0  657  387     5.393067      44      1\n",
      "9         0  752  311     2.792527      41      1\n",
      "\n",
      "Shape of the first image: (512, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "# Inspect the loaded data\n",
    "print(\"Images DataFrame shape:\")\n",
    "print(images_df.shape)\n",
    "print(\"First image\")\n",
    "print(images_df.head(1))\n",
    "print(\"\\nLabels DataFrame shape:\")\n",
    "print(labels_df.shape)\n",
    "print(\"\\nFirst label:\")\n",
    "print(labels_df.head(10))\n",
    "# Access the image array of the first row\n",
    "first_image = images_df['image'].iloc[0]\n",
    "\n",
    "print(f\"\\nShape of the first image: {first_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "799a2648-8d4c-4187-bd8f-ca38d9545da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of the first SCALED image: (256, 512, 3)\n",
      "images_df    id                                              image  \\\n",
      "0   0  [[[17, 123, 57], [18, 124, 58], [18, 124, 58],...   \n",
      "1   1  [[[17, 123, 57], [18, 124, 58], [18, 124, 58],...   \n",
      "2   2  [[[17, 123, 57], [18, 124, 58], [18, 124, 58],...   \n",
      "3   3  [[[17, 123, 57], [18, 124, 58], [18, 124, 58],...   \n",
      "4   4  [[[17, 123, 57], [18, 124, 58], [18, 124, 58],...   \n",
      "5   5  [[[17, 123, 57], [18, 124, 58], [18, 124, 58],...   \n",
      "6   6  [[[17, 123, 57], [18, 124, 58], [18, 124, 58],...   \n",
      "7   7  [[[17, 123, 57], [18, 124, 58], [18, 124, 58],...   \n",
      "8   8  [[[17, 123, 57], [18, 124, 58], [18, 124, 58],...   \n",
      "9   9  [[[17, 123, 57], [18, 124, 58], [18, 124, 58],...   \n",
      "\n",
      "                                        scaled_image  \n",
      "0  [[[18, 124, 58], [18, 124, 58], [17, 123, 57],...  \n",
      "1  [[[18, 124, 58], [18, 124, 58], [17, 123, 57],...  \n",
      "2  [[[18, 124, 58], [18, 124, 58], [17, 123, 57],...  \n",
      "3  [[[18, 124, 58], [18, 124, 58], [17, 123, 57],...  \n",
      "4  [[[18, 124, 58], [18, 124, 58], [17, 123, 57],...  \n",
      "5  [[[18, 124, 58], [18, 124, 58], [17, 123, 57],...  \n",
      "6  [[[18, 124, 58], [18, 124, 58], [17, 123, 57],...  \n",
      "7  [[[18, 124, 58], [18, 124, 58], [17, 123, 57],...  \n",
      "8  [[[18, 124, 58], [18, 124, 58], [17, 123, 57],...  \n",
      "9  [[[18, 124, 58], [18, 124, 58], [17, 123, 57],...  \n"
     ]
    }
   ],
   "source": [
    "def scale_image(image, scale_factor=0.5):\n",
    "    width = int(image.shape[1] * scale_factor)\n",
    "    height = int(image.shape[0] * scale_factor)\n",
    "    resized_image = cv2.resize(image, (width, height))\n",
    "    return resized_image\n",
    "\n",
    "images_df['scaled_image'] = images_df['image'].apply(scale_image)\n",
    "\n",
    "# Access the image array of the first row\n",
    "first_image_scaled = images_df['scaled_image'].iloc[0]\n",
    "\n",
    "print(f\"\\nShape of the first SCALED image: {first_image_scaled.shape}\")\n",
    "\n",
    "print(\"images_df\", images_df.head(10))\n",
    "# print(\"val_images\", len(val_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e244c171-5423-4f40-9f45-57da20f9bb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'scaled_image' column of images_df:\n",
      "0\n",
      "Missing values in 'image' column of images_df:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in 'scaled_image' column of images_df:\")\n",
    "print(images_df['scaled_image'].isnull().sum())\n",
    "\n",
    "print(\"Missing values in 'image' column of images_df:\")\n",
    "print(images_df['image'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c6d4876-7ef0-4150-88a5-0c690ac64212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train_images: 9200\n",
      "Length of val_images: 2300\n",
      "Length of train_labels: 9200\n",
      "Length of val_labels: 2300\n",
      "First train data sample         id                                              image  \\\n",
      "11351  493  [[[17, 123, 57], [18, 124, 58], [18, 124, 58],...   \n",
      "\n",
      "                                            scaled_image  image_id    x    y  \\\n",
      "11351  [[[18, 124, 58], [18, 124, 58], [17, 123, 57],...       493  864  115   \n",
      "\n",
      "       orientation  radius  class  \n",
      "11351          0.0      47      2  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a list to store the merged DataFrames for each image\n",
    "merged_dfs = []\n",
    "\n",
    "for image_id in images_df['id'].unique():\n",
    "    image_data = images_df[images_df['id'] == image_id]\n",
    "    label_data = labels_df[labels_df['image_id'] == image_id]\n",
    "    \n",
    "    merged_df = pd.merge(image_data, label_data, left_on='id', right_on='image_id', how='inner')\n",
    "    merged_dfs.append(merged_df)\n",
    "\n",
    "final_df = pd.concat(merged_dfs, ignore_index=True)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data = train_test_split(final_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Separate the images and labels for training and validation sets\n",
    "train_images = train_data['scaled_image'].tolist()\n",
    "val_images = val_data['scaled_image'].tolist()\n",
    "train_labels = train_data.drop(['id', 'scaled_image'], axis=1)\n",
    "val_labels = val_data.drop(['id', 'scaled_image'], axis=1)\n",
    "\n",
    "print(\"Length of train_images:\", len(train_images))\n",
    "print(\"Length of val_images:\", len(val_images))\n",
    "print(\"Length of train_labels:\", len(train_labels))\n",
    "print(\"Length of val_labels:\", len(val_labels))\n",
    "print(\"First train data sample\", train_data.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26a2d7c4-c5df-4fb8-944c-38c946557d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (9200, 256, 512, 3)\n",
      "y_train shape: (9200, 7)\n",
      "X_val shape: (2300, 256, 512, 3)\n",
      "y_val shape: (2300, 7)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Extract the label values and normalize coordinates and radius\n",
    "X_train = np.array(train_images)\n",
    "y_train = []\n",
    "\n",
    "for _, row in train_data.iterrows():\n",
    "    scaled_image = row['scaled_image']\n",
    "    \n",
    "    # Extract the label values\n",
    "    x = row['x'] / scaled_image.shape[1]  # Normalize x coordinates\n",
    "    y = row['y'] / scaled_image.shape[0]  # Normalize y coordinates\n",
    "    orientation = row['orientation']\n",
    "    radius = row['radius'] / (scaled_image.shape[0] + scaled_image.shape[1]) / 2  # Normalize radius\n",
    "    class_label = row['class']\n",
    "    \n",
    "    # One-hot encode the class label\n",
    "    class_one_hot = to_categorical(class_label, num_classes=3)  # Assuming you have 3 classes\n",
    "    \n",
    "    # Create the label array\n",
    "    label = np.concatenate(([x, y, orientation, radius], class_one_hot))\n",
    "    y_train.append(label)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Repeat the process for validation data\n",
    "X_val = np.array(val_images)\n",
    "y_val = []\n",
    "\n",
    "for _, row in val_data.iterrows():\n",
    "    scaled_image = row['scaled_image']\n",
    "    \n",
    "    # Extract the label values\n",
    "    x = row['x'] / scaled_image.shape[1]  # Normalize x coordinates\n",
    "    y = row['y'] / scaled_image.shape[0]  # Normalize y coordinates\n",
    "    orientation = row['orientation']\n",
    "    radius = row['radius'] / (scaled_image.shape[0] + scaled_image.shape[1]) / 2  # Normalize radius\n",
    "    class_label = row['class']\n",
    "    \n",
    "    # One-hot encode the class label\n",
    "    class_one_hot = to_categorical(class_label, num_classes=3)  # Assuming you have 3 classes\n",
    "    \n",
    "    # Create the label array\n",
    "    label = np.concatenate(([x, y, orientation, radius], class_one_hot))\n",
    "    y_val.append(label)\n",
    "\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b9064d96-c5be-420f-aac6-f70c7b5b8096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(22036) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (2.16.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (4.10.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (49.2.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: keras>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (3.1.1)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (0.36.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.62.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: optree in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (7.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from rich->keras>=3.0.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2e90200-3178-4805-91c7-15ae36cf000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def create_cnn_backbone(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    x = layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
    "    print(\"Conv2D_1 output shape:\", x.shape)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    print(\"MaxPooling2D_1 output shape:\", x.shape)\n",
    "    x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    print(\"Conv2D_2 output shape:\", x.shape)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    print(\"MaxPooling2D_2 output shape:\", x.shape)\n",
    "    x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    print(\"Conv2D_3 output shape:\", x.shape)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    print(\"MaxPooling2D_3 output shape:\", x.shape)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    print(\"Flatten output shape:\", x.shape)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    print(\"Dense_1 output shape:\", x.shape)\n",
    "    outputs = layers.Dense(5, activation='linear')(x)\n",
    "    print(\"Dense_2 output shape:\", outputs.shape)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1742eef-3ff8-4c9f-a005-91ed40786f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy, sparse_categorical_crossentropy, mse\n",
    "\n",
    "def yolo_loss(y_true, y_pred):\n",
    "    # Extract the different components from the ground truth and predicted tensors\n",
    "    x_true, y_true, orient_true, radius_true = y_true[..., 0], y_true[..., 1], y_true[..., 2], y_true[..., 3]\n",
    "    class_true = y_true[..., 4:]\n",
    "    x_pred, y_pred, orient_pred, radius_pred = y_pred[..., 0], y_pred[..., 1], y_pred[..., 2], y_pred[..., 3]\n",
    "    class_pred = y_pred[..., 4:]\n",
    "    \n",
    "    # Coordinate loss\n",
    "    coord_loss = mse(x_true, x_pred) + mse(y_true, y_pred)\n",
    "    \n",
    "    # Orientation loss\n",
    "    orient_loss = mse(orient_true, orient_pred)\n",
    "    \n",
    "    # Radius loss\n",
    "    radius_loss = mse(radius_true, radius_pred)\n",
    "    \n",
    "    # Class loss\n",
    "    class_loss = categorical_crossentropy(class_true, class_pred)\n",
    "    \n",
    "    # Combine the losses\n",
    "    total_loss = coord_loss + orient_loss + radius_loss + class_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718ea561-89e7-4728-a2e3-db32faba1a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2D_1 output shape: (None, 256, 512, 32)\n",
      "MaxPooling2D_1 output shape: (None, 128, 256, 32)\n",
      "Conv2D_2 output shape: (None, 128, 256, 64)\n",
      "MaxPooling2D_2 output shape: (None, 64, 128, 64)\n",
      "Conv2D_3 output shape: (None, 64, 128, 128)\n",
      "MaxPooling2D_3 output shape: (None, 32, 64, 128)\n",
      "Flatten output shape: (None, 262144)\n",
      "Dense_1 output shape: (None, 256)\n",
      "Dense_2 output shape: (None, 5)\n",
      "Epoch 1/10\n",
      "\u001b[1m 20/288\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12:41\u001b[0m 3s/step - loss: 25730524.0000"
     ]
    }
   ],
   "source": [
    "model = create_cnn_backbone(input_shape=(256, 512, 3))\n",
    "model.compile(optimizer='adam', loss=yolo_loss)\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a9e4e2-8259-4719-b396-7270925ebc20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
